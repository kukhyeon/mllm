{
    "Qwen1.5":{
        "0.5B":{
            "FP32":{
                "url":"https://huggingface.co/mllmTeam/qwen-1.5-0.5b-mllm/resolve/main/qwen-1.5-0.5b-fp32.mllm",
                "output":"models/qwen-1.5-0.5b-fp32.mllm",
                "size":"2.48GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/mllmTeam/qwen-1.5-0.5b-mllm/resolve/main/qwen-1.5-0.5b-q4_k.mllm",
                "output":"models/qwen-1.5-0.5b-q4k.mllm",
                "size":"908MB",
                "description":"Q4K"
            }
        },
        "1.8B":{
            "FP32":{
                "url":"https://huggingface.co/mllmTeam/qwen-1.5-1.8b-mllm/resolve/main/qwen-1.5-1.8b-fp32.mllm",
                "output":"models/qwen-1.5-1.8b-fp32.mllm",
                "size":"7.35GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/mllmTeam/qwen-1.5-1.8b-mllm/resolve/main/qwen-1.5-1.8b-q4_k.mllm",
                "output":"models/qwen-1.5-1.8b-q4k.mllm",
                "size":"3.06GB",
                "description":"Q4K"
            }
        },
        "1.8B-CHAT":{
            "INT4":{
                "url":"https://huggingface.co/mllmTeam/qwen-1.5-1.8b-chat-mllm/resolve/main/qwen-1.5-1.8b-chat-q4k.mllm",
                "output":"models/qwen-1.5-1.8b-q4k-chat.mllm",
                "size":"3.06GB",
                "description":"Q4K"
            }
        }
    },
    "Qwen2.5":{
        "0.5B":{
            "FP32":{
                "url":"https://huggingface.co/kjh2159/Qwen2.5-0.5B-MLLM/resolve/main/qwen-2.5-0.5b-fp16.mllm",
                "output":"models/qwen-1.5-0.5b-fp32.mllm",
                "size":"1.98GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/kjh2159/Qwen2.5-0.5B-MLLM/resolve/main/qwen-2.5-0.5b-q4_0.mllm",
                "output":"models/qwen-2.5-0.5b-q40.mllm",
                "size":"1.11GB",
                "description":"Q40"
            }
        },
        "0.5B-INST":{
            "FP32":{
                "url":"https://huggingface.co/kjh2159/Qwen2.5-0.5B-Instruct-MLLM/resolve/main/qwen2.5-0.5b-instruct-fp32.mllm",
                "output":"models/qwen-1.5-0.5b-fp32-inst.mllm",
                "size":"1.98GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/kjh2159/Qwen2.5-0.5B-Instruct-MLLM/resolve/main/qwen2.5-0.5b-instruct_q4_0.mllm",
                "output":"models/qwen-2.5-0.5b-q40-inst.mllm",
                "size":"1.11GB",
                "description":"Q40"
            }
        },
        "1.5B-INST":{
            "FP32":{
                "url":"https://huggingface.co/mllmTeam/qwen-2.5-1.5b-mllm/resolve/main/qwen-2.5-1.5b-instruct-fp32.mllm",
                "output":"models/qwen-2.5-1.5b-fp32-inst.mllm",
                "size":"6.17GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/mllmTeam/qwen-2.5-1.5b-mllm/resolve/main/qwen-2.5-1.5b-instruct-q4_k.mllm",
                "output":"models/qwen-2.5-1.5b-q4k-inst.mllm",
                "size":"1.77GB",
                "description":"Q4K"
            }
        }
    },
    "Qwen3":{
        "0.6B":{
            "FP32":{
                "url":"https://huggingface.co/mllmTeam/qwen-3-0.6b-mllm/resolve/main/qwen-3-0.6b-fp32.mllm",
                "output":"models/qwen-3-0.6b-fp32.mllm",
                "size":"3.01GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/mllmTeam/qwen-3-0.6b-mllm/resolve/main/qwen-3-0.6b-q4_k.mllm",
                "output":"models/qwen-3-0.6b-q4k.mllm",
                "size":"1.29GB",
                "description":"Q4K"
            }
        },
        "1.7B":{
            "FP32":{
                "url":"https://huggingface.co/kjh2159/Qwen3-1.7B-MLLM/resolve/main/qwen3-1.7b-fp16.mllm",
                "output":"models/qwen-3-1.7b-fp32.mllm",
                "size":"8.13GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/kjh2159/Qwen3-1.7B-MLLM/resolve/main/qwen3-1.7b-q4_k.mllm",
                "output":"models/qwen-3-1.7b-q4k.mllm",
                "size":"3.39GB",
                "description":"Q4K"
            }
        }
    },
    "Llama3.2":{
        "1B-INST":{
            "FP32":{
                "url":"https://huggingface.co/mllmTeam/llama-3.2-1b-mllm/resolve/main/llama-3.2-1b-instruct-fp32.mllm",
                "output":"models/llama-3.2-1b-fp32-inst.mllm",
                "size":"4.94GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/mllmTeam/llama-3.2-1b-mllm/resolve/main/llama-3.2-1b-instruct_q4_k.mllm",
                "output":"models/llama-3.2-1b-q4k-inst.mllm",
                "size":"769MB",
                "description":"Q4K"
            }
        },
        "3B-INST":{
            "FP32":{
                "url":"https://huggingface.co/mllmTeam/llama-3.2-3b-mllm/resolve/main/llama-3.2-3b-instruct_fp32.mllm",
                "output":"models/llama-3.2-3b-fp32-inst.mllm",
                "size":"12.9GB",
                "description":""
            },
            "INT4":{
                "url":"https://huggingface.co/kjh2159/Qwen3-1.7B-MLLM/resolve/main/qwen3-1.7b-q4_k.mllm",
                "output":"models/llama-3.2-3b-q4k-inst.mllm",
                "size":"2.01GB",
                "description":"Q4K"
            }
        }
    }
}