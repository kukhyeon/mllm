Quantize 290 params to Q4_0
Quantize param model.embed_tokens.weight to F32	  size:544538624
Quantize param model.layers.0.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.0.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.0.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.0.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.0.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.0.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.0.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.0.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.0.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.0.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.0.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.0.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.1.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.1.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.1.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.1.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.1.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.1.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.1.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.1.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.1.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.1.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.1.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.1.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.10.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.10.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.10.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.10.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.10.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.10.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.10.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.10.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.10.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.10.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.10.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.10.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.11.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.11.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.11.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.11.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.11.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.11.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.11.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.11.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.11.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.11.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.11.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.11.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.12.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.12.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.12.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.12.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.12.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.12.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.12.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.12.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.12.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.12.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.12.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.12.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.13.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.13.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.13.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.13.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.13.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.13.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.13.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.13.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.13.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.13.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.13.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.13.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.14.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.14.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.14.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.14.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.14.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.14.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.14.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.14.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.14.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.14.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.14.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.14.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.15.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.15.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.15.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.15.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.15.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.15.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.15.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.15.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.15.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.15.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.15.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.15.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.16.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.16.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.16.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.16.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.16.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.16.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.16.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.16.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.16.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.16.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.16.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.16.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.17.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.17.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.17.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.17.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.17.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.17.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.17.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.17.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.17.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.17.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.17.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.17.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.18.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.18.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.18.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.18.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.18.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.18.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.18.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.18.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.18.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.18.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.18.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.18.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.19.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.19.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.19.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.19.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.19.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.19.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.19.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.19.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.19.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.19.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.19.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.19.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.2.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.2.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.2.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.2.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.2.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.2.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.2.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.2.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.2.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.2.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.2.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.2.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.20.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.20.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.20.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.20.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.20.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.20.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.20.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.20.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.20.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.20.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.20.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.20.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.21.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.21.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.21.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.21.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.21.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.21.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.21.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.21.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.21.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.21.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.21.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.21.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.22.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.22.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.22.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.22.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.22.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.22.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.22.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.22.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.22.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.22.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.22.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.22.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.23.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.23.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.23.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.23.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.23.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.23.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.23.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.23.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.23.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.23.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.23.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.23.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.3.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.3.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.3.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.3.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.3.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.3.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.3.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.3.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.3.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.3.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.3.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.3.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.4.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.4.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.4.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.4.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.4.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.4.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.4.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.4.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.4.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.4.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.4.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.4.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.5.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.5.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.5.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.5.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.5.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.5.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.5.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.5.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.5.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.5.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.5.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.5.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.6.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.6.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.6.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.6.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.6.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.6.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.6.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.6.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.6.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.6.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.6.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.6.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.7.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.7.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.7.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.7.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.7.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.7.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.7.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.7.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.7.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.7.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.7.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.7.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.8.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.8.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.8.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.8.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.8.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.8.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.8.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.8.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.8.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.8.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.8.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.8.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.layers.9.input_layernorm.weight to F32	  size:3584
Quantize param model.layers.9.mlp.down_proj.weight to Q4_0	  size:2451456 type:Q4_0
Quantize param model.layers.9.mlp.gate_proj.weight to F32	  size:17432576
Quantize param model.layers.9.mlp.up_proj.weight to Q4_0	  size:2451456
Quantize param model.layers.9.post_attention_layernorm.weight to F32	  size:3584
Quantize param model.layers.9.self_attn.k_proj.bias to F32	  size:512
Quantize param model.layers.9.self_attn.k_proj.weight to Q4_0	  size:64512
Quantize param model.layers.9.self_attn.o_proj.weight to Q4_0	  size:451584
Quantize param model.layers.9.self_attn.q_proj.bias to F32	  size:3584
Quantize param model.layers.9.self_attn.q_proj.weight to Q4_0	  size:451584
Quantize param model.layers.9.self_attn.v_proj.bias to F32	  size:512
Quantize param model.layers.9.self_attn.v_proj.weight to Q4_0	  size:64512 type:Q4_0
Quantize param model.norm.weight to F32	  size:3584
write param model.embed_tokens.weight size 544538624 offset 17886 type 0
write param model.layers.0.input_layernorm.weight size 3584 offset 544556510 type 0
write param model.layers.0.mlp.down_proj.weight size 2451456 offset 544560094 type 2
write param model.layers.0.mlp.gate_proj.weight size 17432576 offset 547011550 type 0
write param model.layers.0.mlp.up_proj.weight size 2451456 offset 564444126 type 2
write param model.layers.0.post_attention_layernorm.weight size 3584 offset 566895582 type 0
write param model.layers.0.self_attn.k_proj.bias size 512 offset 566899166 type 0
write param model.layers.0.self_attn.k_proj.weight size 64512 offset 566899678 type 2
write param model.layers.0.self_attn.o_proj.weight size 451584 offset 566964190 type 2
write param model.layers.0.self_attn.q_proj.bias size 3584 offset 567415774 type 0
write param model.layers.0.self_attn.q_proj.weight size 451584 offset 567419358 type 2
write param model.layers.0.self_attn.v_proj.bias size 512 offset 567870942 type 0
write param model.layers.0.self_attn.v_proj.weight size 64512 offset 567871454 type 2
write param model.layers.1.input_layernorm.weight size 3584 offset 567935966 type 0
write param model.layers.1.mlp.down_proj.weight size 2451456 offset 567939550 type 2
write param model.layers.1.mlp.gate_proj.weight size 17432576 offset 570391006 type 0
write param model.layers.1.mlp.up_proj.weight size 2451456 offset 587823582 type 2
write param model.layers.1.post_attention_layernorm.weight size 3584 offset 590275038 type 0
write param model.layers.1.self_attn.k_proj.bias size 512 offset 590278622 type 0
write param model.layers.1.self_attn.k_proj.weight size 64512 offset 590279134 type 2
write param model.layers.1.self_attn.o_proj.weight size 451584 offset 590343646 type 2
write param model.layers.1.self_attn.q_proj.bias size 3584 offset 590795230 type 0
write param model.layers.1.self_attn.q_proj.weight size 451584 offset 590798814 type 2
write param model.layers.1.self_attn.v_proj.bias size 512 offset 591250398 type 0
write param model.layers.1.self_attn.v_proj.weight size 64512 offset 591250910 type 2
write param model.layers.10.input_layernorm.weight size 3584 offset 591315422 type 0
write param model.layers.10.mlp.down_proj.weight size 2451456 offset 591319006 type 2
write param model.layers.10.mlp.gate_proj.weight size 17432576 offset 593770462 type 0
write param model.layers.10.mlp.up_proj.weight size 2451456 offset 611203038 type 2
write param model.layers.10.post_attention_layernorm.weight size 3584 offset 613654494 type 0
write param model.layers.10.self_attn.k_proj.bias size 512 offset 613658078 type 0
write param model.layers.10.self_attn.k_proj.weight size 64512 offset 613658590 type 2
write param model.layers.10.self_attn.o_proj.weight size 451584 offset 613723102 type 2
write param model.layers.10.self_attn.q_proj.bias size 3584 offset 614174686 type 0
write param model.layers.10.self_attn.q_proj.weight size 451584 offset 614178270 type 2
write param model.layers.10.self_attn.v_proj.bias size 512 offset 614629854 type 0
write param model.layers.10.self_attn.v_proj.weight size 64512 offset 614630366 type 2
write param model.layers.11.input_layernorm.weight size 3584 offset 614694878 type 0
write param model.layers.11.mlp.down_proj.weight size 2451456 offset 614698462 type 2
write param model.layers.11.mlp.gate_proj.weight size 17432576 offset 617149918 type 0
write param model.layers.11.mlp.up_proj.weight size 2451456 offset 634582494 type 2
write param model.layers.11.post_attention_layernorm.weight size 3584 offset 637033950 type 0
write param model.layers.11.self_attn.k_proj.bias size 512 offset 637037534 type 0
write param model.layers.11.self_attn.k_proj.weight size 64512 offset 637038046 type 2
write param model.layers.11.self_attn.o_proj.weight size 451584 offset 637102558 type 2
write param model.layers.11.self_attn.q_proj.bias size 3584 offset 637554142 type 0
write param model.layers.11.self_attn.q_proj.weight size 451584 offset 637557726 type 2
write param model.layers.11.self_attn.v_proj.bias size 512 offset 638009310 type 0
write param model.layers.11.self_attn.v_proj.weight size 64512 offset 638009822 type 2
write param model.layers.12.input_layernorm.weight size 3584 offset 638074334 type 0
write param model.layers.12.mlp.down_proj.weight size 2451456 offset 638077918 type 2
write param model.layers.12.mlp.gate_proj.weight size 17432576 offset 640529374 type 0
write param model.layers.12.mlp.up_proj.weight size 2451456 offset 657961950 type 2
write param model.layers.12.post_attention_layernorm.weight size 3584 offset 660413406 type 0
write param model.layers.12.self_attn.k_proj.bias size 512 offset 660416990 type 0
write param model.layers.12.self_attn.k_proj.weight size 64512 offset 660417502 type 2
write param model.layers.12.self_attn.o_proj.weight size 451584 offset 660482014 type 2
write param model.layers.12.self_attn.q_proj.bias size 3584 offset 660933598 type 0
write param model.layers.12.self_attn.q_proj.weight size 451584 offset 660937182 type 2
write param model.layers.12.self_attn.v_proj.bias size 512 offset 661388766 type 0
write param model.layers.12.self_attn.v_proj.weight size 64512 offset 661389278 type 2
write param model.layers.13.input_layernorm.weight size 3584 offset 661453790 type 0
write param model.layers.13.mlp.down_proj.weight size 2451456 offset 661457374 type 2
write param model.layers.13.mlp.gate_proj.weight size 17432576 offset 663908830 type 0
write param model.layers.13.mlp.up_proj.weight size 2451456 offset 681341406 type 2
write param model.layers.13.post_attention_layernorm.weight size 3584 offset 683792862 type 0
write param model.layers.13.self_attn.k_proj.bias size 512 offset 683796446 type 0
write param model.layers.13.self_attn.k_proj.weight size 64512 offset 683796958 type 2
write param model.layers.13.self_attn.o_proj.weight size 451584 offset 683861470 type 2
write param model.layers.13.self_attn.q_proj.bias size 3584 offset 684313054 type 0
write param model.layers.13.self_attn.q_proj.weight size 451584 offset 684316638 type 2
write param model.layers.13.self_attn.v_proj.bias size 512 offset 684768222 type 0
write param model.layers.13.self_attn.v_proj.weight size 64512 offset 684768734 type 2
write param model.layers.14.input_layernorm.weight size 3584 offset 684833246 type 0
write param model.layers.14.mlp.down_proj.weight size 2451456 offset 684836830 type 2
write param model.layers.14.mlp.gate_proj.weight size 17432576 offset 687288286 type 0
write param model.layers.14.mlp.up_proj.weight size 2451456 offset 704720862 type 2
write param model.layers.14.post_attention_layernorm.weight size 3584 offset 707172318 type 0
write param model.layers.14.self_attn.k_proj.bias size 512 offset 707175902 type 0
write param model.layers.14.self_attn.k_proj.weight size 64512 offset 707176414 type 2
write param model.layers.14.self_attn.o_proj.weight size 451584 offset 707240926 type 2
write param model.layers.14.self_attn.q_proj.bias size 3584 offset 707692510 type 0
write param model.layers.14.self_attn.q_proj.weight size 451584 offset 707696094 type 2
write param model.layers.14.self_attn.v_proj.bias size 512 offset 708147678 type 0
write param model.layers.14.self_attn.v_proj.weight size 64512 offset 708148190 type 2
write param model.layers.15.input_layernorm.weight size 3584 offset 708212702 type 0
write param model.layers.15.mlp.down_proj.weight size 2451456 offset 708216286 type 2
write param model.layers.15.mlp.gate_proj.weight size 17432576 offset 710667742 type 0
write param model.layers.15.mlp.up_proj.weight size 2451456 offset 728100318 type 2
write param model.layers.15.post_attention_layernorm.weight size 3584 offset 730551774 type 0
write param model.layers.15.self_attn.k_proj.bias size 512 offset 730555358 type 0
write param model.layers.15.self_attn.k_proj.weight size 64512 offset 730555870 type 2
write param model.layers.15.self_attn.o_proj.weight size 451584 offset 730620382 type 2
write param model.layers.15.self_attn.q_proj.bias size 3584 offset 731071966 type 0
write param model.layers.15.self_attn.q_proj.weight size 451584 offset 731075550 type 2
write param model.layers.15.self_attn.v_proj.bias size 512 offset 731527134 type 0
write param model.layers.15.self_attn.v_proj.weight size 64512 offset 731527646 type 2
write param model.layers.16.input_layernorm.weight size 3584 offset 731592158 type 0
write param model.layers.16.mlp.down_proj.weight size 2451456 offset 731595742 type 2
write param model.layers.16.mlp.gate_proj.weight size 17432576 offset 734047198 type 0
write param model.layers.16.mlp.up_proj.weight size 2451456 offset 751479774 type 2
write param model.layers.16.post_attention_layernorm.weight size 3584 offset 753931230 type 0
write param model.layers.16.self_attn.k_proj.bias size 512 offset 753934814 type 0
write param model.layers.16.self_attn.k_proj.weight size 64512 offset 753935326 type 2
write param model.layers.16.self_attn.o_proj.weight size 451584 offset 753999838 type 2
write param model.layers.16.self_attn.q_proj.bias size 3584 offset 754451422 type 0
write param model.layers.16.self_attn.q_proj.weight size 451584 offset 754455006 type 2
write param model.layers.16.self_attn.v_proj.bias size 512 offset 754906590 type 0
write param model.layers.16.self_attn.v_proj.weight size 64512 offset 754907102 type 2
write param model.layers.17.input_layernorm.weight size 3584 offset 754971614 type 0
write param model.layers.17.mlp.down_proj.weight size 2451456 offset 754975198 type 2
write param model.layers.17.mlp.gate_proj.weight size 17432576 offset 757426654 type 0
write param model.layers.17.mlp.up_proj.weight size 2451456 offset 774859230 type 2
write param model.layers.17.post_attention_layernorm.weight size 3584 offset 777310686 type 0
write param model.layers.17.self_attn.k_proj.bias size 512 offset 777314270 type 0
write param model.layers.17.self_attn.k_proj.weight size 64512 offset 777314782 type 2
write param model.layers.17.self_attn.o_proj.weight size 451584 offset 777379294 type 2
write param model.layers.17.self_attn.q_proj.bias size 3584 offset 777830878 type 0
write param model.layers.17.self_attn.q_proj.weight size 451584 offset 777834462 type 2
write param model.layers.17.self_attn.v_proj.bias size 512 offset 778286046 type 0
write param model.layers.17.self_attn.v_proj.weight size 64512 offset 778286558 type 2
write param model.layers.18.input_layernorm.weight size 3584 offset 778351070 type 0
write param model.layers.18.mlp.down_proj.weight size 2451456 offset 778354654 type 2
write param model.layers.18.mlp.gate_proj.weight size 17432576 offset 780806110 type 0
write param model.layers.18.mlp.up_proj.weight size 2451456 offset 798238686 type 2
write param model.layers.18.post_attention_layernorm.weight size 3584 offset 800690142 type 0
write param model.layers.18.self_attn.k_proj.bias size 512 offset 800693726 type 0
write param model.layers.18.self_attn.k_proj.weight size 64512 offset 800694238 type 2
write param model.layers.18.self_attn.o_proj.weight size 451584 offset 800758750 type 2
write param model.layers.18.self_attn.q_proj.bias size 3584 offset 801210334 type 0
write param model.layers.18.self_attn.q_proj.weight size 451584 offset 801213918 type 2
write param model.layers.18.self_attn.v_proj.bias size 512 offset 801665502 type 0
write param model.layers.18.self_attn.v_proj.weight size 64512 offset 801666014 type 2
write param model.layers.19.input_layernorm.weight size 3584 offset 801730526 type 0
write param model.layers.19.mlp.down_proj.weight size 2451456 offset 801734110 type 2
write param model.layers.19.mlp.gate_proj.weight size 17432576 offset 804185566 type 0
write param model.layers.19.mlp.up_proj.weight size 2451456 offset 821618142 type 2
write param model.layers.19.post_attention_layernorm.weight size 3584 offset 824069598 type 0
write param model.layers.19.self_attn.k_proj.bias size 512 offset 824073182 type 0
write param model.layers.19.self_attn.k_proj.weight size 64512 offset 824073694 type 2
write param model.layers.19.self_attn.o_proj.weight size 451584 offset 824138206 type 2
write param model.layers.19.self_attn.q_proj.bias size 3584 offset 824589790 type 0
write param model.layers.19.self_attn.q_proj.weight size 451584 offset 824593374 type 2
write param model.layers.19.self_attn.v_proj.bias size 512 offset 825044958 type 0
write param model.layers.19.self_attn.v_proj.weight size 64512 offset 825045470 type 2
write param model.layers.2.input_layernorm.weight size 3584 offset 825109982 type 0
write param model.layers.2.mlp.down_proj.weight size 2451456 offset 825113566 type 2
write param model.layers.2.mlp.gate_proj.weight size 17432576 offset 827565022 type 0
write param model.layers.2.mlp.up_proj.weight size 2451456 offset 844997598 type 2
write param model.layers.2.post_attention_layernorm.weight size 3584 offset 847449054 type 0
write param model.layers.2.self_attn.k_proj.bias size 512 offset 847452638 type 0
write param model.layers.2.self_attn.k_proj.weight size 64512 offset 847453150 type 2
write param model.layers.2.self_attn.o_proj.weight size 451584 offset 847517662 type 2
write param model.layers.2.self_attn.q_proj.bias size 3584 offset 847969246 type 0
write param model.layers.2.self_attn.q_proj.weight size 451584 offset 847972830 type 2
write param model.layers.2.self_attn.v_proj.bias size 512 offset 848424414 type 0
write param model.layers.2.self_attn.v_proj.weight size 64512 offset 848424926 type 2
write param model.layers.20.input_layernorm.weight size 3584 offset 848489438 type 0
write param model.layers.20.mlp.down_proj.weight size 2451456 offset 848493022 type 2
write param model.layers.20.mlp.gate_proj.weight size 17432576 offset 850944478 type 0
write param model.layers.20.mlp.up_proj.weight size 2451456 offset 868377054 type 2
write param model.layers.20.post_attention_layernorm.weight size 3584 offset 870828510 type 0
write param model.layers.20.self_attn.k_proj.bias size 512 offset 870832094 type 0
write param model.layers.20.self_attn.k_proj.weight size 64512 offset 870832606 type 2
write param model.layers.20.self_attn.o_proj.weight size 451584 offset 870897118 type 2
write param model.layers.20.self_attn.q_proj.bias size 3584 offset 871348702 type 0
write param model.layers.20.self_attn.q_proj.weight size 451584 offset 871352286 type 2
write param model.layers.20.self_attn.v_proj.bias size 512 offset 871803870 type 0
write param model.layers.20.self_attn.v_proj.weight size 64512 offset 871804382 type 2
write param model.layers.21.input_layernorm.weight size 3584 offset 871868894 type 0
write param model.layers.21.mlp.down_proj.weight size 2451456 offset 871872478 type 2
write param model.layers.21.mlp.gate_proj.weight size 17432576 offset 874323934 type 0
write param model.layers.21.mlp.up_proj.weight size 2451456 offset 891756510 type 2
write param model.layers.21.post_attention_layernorm.weight size 3584 offset 894207966 type 0
write param model.layers.21.self_attn.k_proj.bias size 512 offset 894211550 type 0
write param model.layers.21.self_attn.k_proj.weight size 64512 offset 894212062 type 2
write param model.layers.21.self_attn.o_proj.weight size 451584 offset 894276574 type 2
write param model.layers.21.self_attn.q_proj.bias size 3584 offset 894728158 type 0
write param model.layers.21.self_attn.q_proj.weight size 451584 offset 894731742 type 2
write param model.layers.21.self_attn.v_proj.bias size 512 offset 895183326 type 0
write param model.layers.21.self_attn.v_proj.weight size 64512 offset 895183838 type 2
write param model.layers.22.input_layernorm.weight size 3584 offset 895248350 type 0
write param model.layers.22.mlp.down_proj.weight size 2451456 offset 895251934 type 2
write param model.layers.22.mlp.gate_proj.weight size 17432576 offset 897703390 type 0
write param model.layers.22.mlp.up_proj.weight size 2451456 offset 915135966 type 2
write param model.layers.22.post_attention_layernorm.weight size 3584 offset 917587422 type 0
write param model.layers.22.self_attn.k_proj.bias size 512 offset 917591006 type 0
write param model.layers.22.self_attn.k_proj.weight size 64512 offset 917591518 type 2
write param model.layers.22.self_attn.o_proj.weight size 451584 offset 917656030 type 2
write param model.layers.22.self_attn.q_proj.bias size 3584 offset 918107614 type 0
write param model.layers.22.self_attn.q_proj.weight size 451584 offset 918111198 type 2
write param model.layers.22.self_attn.v_proj.bias size 512 offset 918562782 type 0
write param model.layers.22.self_attn.v_proj.weight size 64512 offset 918563294 type 2
write param model.layers.23.input_layernorm.weight size 3584 offset 918627806 type 0
write param model.layers.23.mlp.down_proj.weight size 2451456 offset 918631390 type 2
write param model.layers.23.mlp.gate_proj.weight size 17432576 offset 921082846 type 0
write param model.layers.23.mlp.up_proj.weight size 2451456 offset 938515422 type 2
write param model.layers.23.post_attention_layernorm.weight size 3584 offset 940966878 type 0
write param model.layers.23.self_attn.k_proj.bias size 512 offset 940970462 type 0
write param model.layers.23.self_attn.k_proj.weight size 64512 offset 940970974 type 2
write param model.layers.23.self_attn.o_proj.weight size 451584 offset 941035486 type 2
write param model.layers.23.self_attn.q_proj.bias size 3584 offset 941487070 type 0
write param model.layers.23.self_attn.q_proj.weight size 451584 offset 941490654 type 2
write param model.layers.23.self_attn.v_proj.bias size 512 offset 941942238 type 0
write param model.layers.23.self_attn.v_proj.weight size 64512 offset 941942750 type 2
write param model.layers.3.input_layernorm.weight size 3584 offset 942007262 type 0
write param model.layers.3.mlp.down_proj.weight size 2451456 offset 942010846 type 2
write param model.layers.3.mlp.gate_proj.weight size 17432576 offset 944462302 type 0
write param model.layers.3.mlp.up_proj.weight size 2451456 offset 961894878 type 2
write param model.layers.3.post_attention_layernorm.weight size 3584 offset 964346334 type 0
write param model.layers.3.self_attn.k_proj.bias size 512 offset 964349918 type 0
write param model.layers.3.self_attn.k_proj.weight size 64512 offset 964350430 type 2
write param model.layers.3.self_attn.o_proj.weight size 451584 offset 964414942 type 2
write param model.layers.3.self_attn.q_proj.bias size 3584 offset 964866526 type 0
write param model.layers.3.self_attn.q_proj.weight size 451584 offset 964870110 type 2
write param model.layers.3.self_attn.v_proj.bias size 512 offset 965321694 type 0
write param model.layers.3.self_attn.v_proj.weight size 64512 offset 965322206 type 2
write param model.layers.4.input_layernorm.weight size 3584 offset 965386718 type 0
write param model.layers.4.mlp.down_proj.weight size 2451456 offset 965390302 type 2
write param model.layers.4.mlp.gate_proj.weight size 17432576 offset 967841758 type 0
write param model.layers.4.mlp.up_proj.weight size 2451456 offset 985274334 type 2
write param model.layers.4.post_attention_layernorm.weight size 3584 offset 987725790 type 0
write param model.layers.4.self_attn.k_proj.bias size 512 offset 987729374 type 0
write param model.layers.4.self_attn.k_proj.weight size 64512 offset 987729886 type 2
write param model.layers.4.self_attn.o_proj.weight size 451584 offset 987794398 type 2
write param model.layers.4.self_attn.q_proj.bias size 3584 offset 988245982 type 0
write param model.layers.4.self_attn.q_proj.weight size 451584 offset 988249566 type 2
write param model.layers.4.self_attn.v_proj.bias size 512 offset 988701150 type 0
write param model.layers.4.self_attn.v_proj.weight size 64512 offset 988701662 type 2
write param model.layers.5.input_layernorm.weight size 3584 offset 988766174 type 0
write param model.layers.5.mlp.down_proj.weight size 2451456 offset 988769758 type 2
write param model.layers.5.mlp.gate_proj.weight size 17432576 offset 991221214 type 0
write param model.layers.5.mlp.up_proj.weight size 2451456 offset 1008653790 type 2
write param model.layers.5.post_attention_layernorm.weight size 3584 offset 1011105246 type 0
write param model.layers.5.self_attn.k_proj.bias size 512 offset 1011108830 type 0
write param model.layers.5.self_attn.k_proj.weight size 64512 offset 1011109342 type 2
write param model.layers.5.self_attn.o_proj.weight size 451584 offset 1011173854 type 2
write param model.layers.5.self_attn.q_proj.bias size 3584 offset 1011625438 type 0
write param model.layers.5.self_attn.q_proj.weight size 451584 offset 1011629022 type 2
write param model.layers.5.self_attn.v_proj.bias size 512 offset 1012080606 type 0
write param model.layers.5.self_attn.v_proj.weight size 64512 offset 1012081118 type 2
write param model.layers.6.input_layernorm.weight size 3584 offset 1012145630 type 0
write param model.layers.6.mlp.down_proj.weight size 2451456 offset 1012149214 type 2
write param model.layers.6.mlp.gate_proj.weight size 17432576 offset 1014600670 type 0
write param model.layers.6.mlp.up_proj.weight size 2451456 offset 1032033246 type 2
write param model.layers.6.post_attention_layernorm.weight size 3584 offset 1034484702 type 0
write param model.layers.6.self_attn.k_proj.bias size 512 offset 1034488286 type 0
write param model.layers.6.self_attn.k_proj.weight size 64512 offset 1034488798 type 2
write param model.layers.6.self_attn.o_proj.weight size 451584 offset 1034553310 type 2
write param model.layers.6.self_attn.q_proj.bias size 3584 offset 1035004894 type 0
write param model.layers.6.self_attn.q_proj.weight size 451584 offset 1035008478 type 2
write param model.layers.6.self_attn.v_proj.bias size 512 offset 1035460062 type 0
write param model.layers.6.self_attn.v_proj.weight size 64512 offset 1035460574 type 2
write param model.layers.7.input_layernorm.weight size 3584 offset 1035525086 type 0
write param model.layers.7.mlp.down_proj.weight size 2451456 offset 1035528670 type 2
write param model.layers.7.mlp.gate_proj.weight size 17432576 offset 1037980126 type 0
write param model.layers.7.mlp.up_proj.weight size 2451456 offset 1055412702 type 2
write param model.layers.7.post_attention_layernorm.weight size 3584 offset 1057864158 type 0
write param model.layers.7.self_attn.k_proj.bias size 512 offset 1057867742 type 0
write param model.layers.7.self_attn.k_proj.weight size 64512 offset 1057868254 type 2
write param model.layers.7.self_attn.o_proj.weight size 451584 offset 1057932766 type 2
write param model.layers.7.self_attn.q_proj.bias size 3584 offset 1058384350 type 0
write param model.layers.7.self_attn.q_proj.weight size 451584 offset 1058387934 type 2
write param model.layers.7.self_attn.v_proj.bias size 512 offset 1058839518 type 0
write param model.layers.7.self_attn.v_proj.weight size 64512 offset 1058840030 type 2
write param model.layers.8.input_layernorm.weight size 3584 offset 1058904542 type 0
write param model.layers.8.mlp.down_proj.weight size 2451456 offset 1058908126 type 2
write param model.layers.8.mlp.gate_proj.weight size 17432576 offset 1061359582 type 0
write param model.layers.8.mlp.up_proj.weight size 2451456 offset 1078792158 type 2
write param model.layers.8.post_attention_layernorm.weight size 3584 offset 1081243614 type 0
write param model.layers.8.self_attn.k_proj.bias size 512 offset 1081247198 type 0
write param model.layers.8.self_attn.k_proj.weight size 64512 offset 1081247710 type 2
write param model.layers.8.self_attn.o_proj.weight size 451584 offset 1081312222 type 2
write param model.layers.8.self_attn.q_proj.bias size 3584 offset 1081763806 type 0
write param model.layers.8.self_attn.q_proj.weight size 451584 offset 1081767390 type 2
write param model.layers.8.self_attn.v_proj.bias size 512 offset 1082218974 type 0
write param model.layers.8.self_attn.v_proj.weight size 64512 offset 1082219486 type 2
write param model.layers.9.input_layernorm.weight size 3584 offset 1082283998 type 0
write param model.layers.9.mlp.down_proj.weight size 2451456 offset 1082287582 type 2
write param model.layers.9.mlp.gate_proj.weight size 17432576 offset 1084739038 type 0
write param model.layers.9.mlp.up_proj.weight size 2451456 offset 1102171614 type 2
write param model.layers.9.post_attention_layernorm.weight size 3584 offset 1104623070 type 0
write param model.layers.9.self_attn.k_proj.bias size 512 offset 1104626654 type 0
write param model.layers.9.self_attn.k_proj.weight size 64512 offset 1104627166 type 2
write param model.layers.9.self_attn.o_proj.weight size 451584 offset 1104691678 type 2
write param model.layers.9.self_attn.q_proj.bias size 3584 offset 1105143262 type 0
write param model.layers.9.self_attn.q_proj.weight size 451584 offset 1105146846 type 2
write param model.layers.9.self_attn.v_proj.bias size 512 offset 1105598430 type 0
write param model.layers.9.self_attn.v_proj.weight size 64512 offset 1105598942 type 2
write param model.norm.weight size 3584 offset 1105663454 type 0
